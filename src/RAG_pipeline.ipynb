{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23820017-e3f4-4629-82d1-de21193b5cb7",
   "metadata": {},
   "source": [
    "RAG Pipline and implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7424c56-a048-494c-8ace-2a636815ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a421b455-32c2-4c0c-aa8a-858d0412deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f5ea60a-f182-44a8-9309-d87ee57d7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidha\\AppData\\Local\\Temp\\ipykernel_9372\\2114803142.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=50)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "352536a2-4fa9-4227-9065-ee82afc8fbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 11:08:00,917 - INFO - Creating vector store with FAISS...\n",
      "2025-02-23 16:25:08,298 - INFO - Vector store created successfully.\n"
     ]
    }
   ],
   "source": [
    "#loading data from directory,splitting,embedding and storing to vector DB\n",
    "def load_data_from_directory(directory):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            loader = CSVLoader(file_path=file_path)\n",
    "            documents.extend(loader.load())  # Load CSV as documents\n",
    "    return documents\n",
    "DATA_DIR = 'data/cricket_data'\n",
    "# Convert CSVs into a text format for embedding\n",
    "documents = load_data_from_directory(DATA_DIR)\n",
    "\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "logger.info(\"Creating vector store with FAISS...\")\n",
    "vector_store = FAISS.from_documents(split_documents, embedding_model)\n",
    "logger.info(\"Vector store created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e239a-7b9b-41e4-a2bd-ccc33b09d4d3",
   "metadata": {},
   "source": [
    "#data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e1a089-4667-47e3-bcbb-8b5de150a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vector_store = vector_store\n",
    "retriever = data_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f54be96-113b-41cc-a883-c4cca971bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm & RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee11cc30-7a71-4cd5-86dd-c8b7e4e16d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b8150ab2654c2fb4671a96dac96963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df9bc0452224890a012790b64434742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidha\\anaconda3\\envs\\cricket_ai\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sidha\\.cache\\huggingface\\hub\\models--TheBloke--Mistral-7B-Instruct-v0.1-GGUF. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e672d7bf625f456796d89df1b2e846ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384233487c7e46ce9e1f3c7f13280d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mistral-7b-instruct-v0.1.Q2_K.gguf:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.llms import CTransformers\n",
    "# llm = CTransformers(model=\"TheBloke/Llama-2-7B-Chat-GGUF\", model_type=\"llama\", config={\"context_length\": 4096})\n",
    "llm = CTransformers(model=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\", model_type=\"mistral\", config={\"max_new_tokens\": 512, \"context_length\": 2048)\n",
    "# llm = CTransformers(model=\"TheBloke/Llama-2-13B-Chat-GGUF\", model_type=\"llama\")\n",
    "# llm = CTransformers(model=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\", model_type=\"mistral\")\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e19fc68-9bad-4f85-ad5f-0e36682f8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38a38ef-b93f-485f-8bf0-2da5ebb22c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidha\\AppData\\Local\\Temp\\ipykernel_9372\\2756915469.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa_chain.run(\"comparison between Kohli and Rohit in batting stats in IPL.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Kohli has played more ODI matches than Rohit, but Rohit has a higher average score per match. In terms of runs scored, Kohli has the edge, with a total of 11,298 runs and 64 wickets in 195 matches, while Rohit has 7,279 runs and 30 wickets in 134 matches. However, Rohit's average score per match is 55.89, compared to Kohli's 51.25. Rohit also has a higher strike rate of 91.17%, while Kohli's is 90.28%.\n"
     ]
    }
   ],
   "source": [
    "answer = qa_chain.run(\"comparison between Kohli and Rohit in batting stats in IPL.\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8caa5a4d-9817-4291-822e-c5e6c466e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc926098-232d-4198-afb2-49b04bc3c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lg1tm24XpX81GLCuxNnXHaLTQp5Axm7r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28d236c2-87f9-4303-aeb8-5deaaab62a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yusuf Pathan, an Indian cricketer, holds the record for the most sixes in IPL history with 236 sixes.\n"
     ]
    }
   ],
   "source": [
    "answer = qa_chain.run(\"Who has the most sixes in IPL history?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26f5a548-a06d-4f1b-a9b3-fdc0577958c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "India and Pakistan have played 29 matches against each other in various ICC events, with India winning 18 matches, while Pakistan has won 11 matches. The two teams first met in the 1978-79 World Cup tournament, where Pakistan defeated India in a dramatic final match. Since then, the rivalry between the two nations has only intensified, with both teams participating in several high-profile matches and tournaments against each other, including the 2007 World Cup final match, which India won after chasing down the victory target of 438 runs to win by six wickets, becoming the first team to chase down a score above 400 runs to win a World Cup match. In recent years, the two teams have also faced off in several high-profile ODI and Test matches, with India emerging as the dominant force in ICC events against Pakistan.\n"
     ]
    }
   ],
   "source": [
    "answer = qa_chain.run(\"Give me a summary of India vs Pakistan head-to-head in ICC events.\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ca8a9-c29a-46c8-a4d7-fc9872126601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
